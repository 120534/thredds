:source-highlighter: coderay
[[threddsDocs]]

= Feature Collection Internals

_last update 9/15/2013_

== CollectionUpdater

CollectionUpdater manages background tasks. It uses quartz scheduling
library. It triggers CollectionManager to check if things have changed
(aka scan).

[source,java]
----
if (groupName.equals("nocheck")) {
  dcm.updateNocheck();
} else {
  dcm.scan(true);
}
----

In the TDS, the CollectionController recieves messages and tells
CollectionUpdater to trigger a scan or updateNocheck.

== CollectionManager

CollectionManager handles the *collection* element. It manages a dynamic
collection of MFile objects.

It throws an event to TriggerListener’s to communicate changes.

[source,java]
----
 /**
    * A TriggerEvent.proto is sent if protoDataset.change = "cron" has been specified
    * A TriggerEvent.update is sent if a scan has happened and a change in the list of MFiles has occurred,
    *  or an MFile has been updated
    */
    public static interface TriggerListener {
      public void handleCollectionEvent(TriggerEvent event);
    }
    public enum TriggerType {update, proto, updateNocheck }

----

There are three types of events:

* **update**: scan was made and changes were found
* **updateNocheck**: external program (tdm) has found changes and
modified the collection index
* **proto**: time to re-choose the proto dataset

== InvDatasetFeatureCollection

InvDatasetFeatureCollection subclass owns the dataset and the
CollectionManager (dcm), and responds to events from the
CollectionManager:

[source,java]
----
public void handleCollectionEvent(CollectionManager.TriggerEvent event) {
 if (event.getType() == CollectionManager.TriggerType.updateNocheck)
   update(CollectionManager.Force.nocheck);

 else if (event.getType() == CollectionManager.TriggerType.update)
   update(CollectionManager.Force.always);

 else if (event.getType() == CollectionManager.TriggerType.proto)
   updateProto();
}

  public enum Force {always,   // force new index
                     test,     // test if new index is needed
                     nocheck } // if index exists, use it
----

There are 3 subclasses of InvDatasetFeatureCollection:

* **grib**: dataset is a GribCollection
* **point**; dataset is a FeatureDatasetPoint
* **fmrc**: dataset is an Fmrc

== Updating

There are several ways to update a feature collection when it changes,
specified by the *update* and/or *tdm* element:

. *recheckAfter* ** attribute**:** causes a directory scan whenever a
request comes in and the specified time has elapsed since the last scan.
The request waits until the scan is finished and a new collection is
built (if needed). This is called __synchronous updating__.
. *rescan* and *startup* attributes: uses a background thread to keep
the collection updated, so that requests never wait. This is called
__asynchronous updating__.
. *trigger* attribute: allows a trigger to be sent to the TDS to tell
it to scan the collection. If scan finds changes, an *update* event is
made. This is called __user controlled updating__.
.  **tdm**: external program does the actual updating of the indexes
(currently only for grib), sends a trigger that causes an
*updateNocheck* event. This is called __external program updating__.

=== Implementation

. **first request:**
. **recheckAfter**: is implemented by calling **checkState**() for
each request which calls **dcm.scanIfNeeded()**. That returns true only
if recheck is set and its the first time or a scan shows that something
changed. If true, then:
.. **grib**: updateCollection(Force.**nocheck** or Force.**test**)
. **update(Force.nocheck**);
. **update(Force.test**);
. **update(Force.always**);
.. manager.scan() -> factory(**always**) or nothing

. **update(Force.always**);
.. **nocheck**: manager.updateNocheck() -> factory(**nocheck**)
.. **test**: manager.scan() -> factory(**always**). since dcm hasnt
been populated, this will always recreate the index PROBLEM?
. **update(Force.test**);
.. CollectionController calls CollectionUpdater.triggerUpdate(name,
trigger)
.. CollectionUpdater starts background task, which runs and calls
... **nocheck**: manager.updateNocheck() -> factory(**nocheck**)
... **test**: manager.scan() -> factory(**always**) or nothing

== External calls - must call checkState()

* OK public java.util.List<InvDataset> getDatasets(); // override catRef - defer construction until needed.
* public ucar.nc2.dt.GridDataset getGridDataset(String matchPath)
* public NetcdfDataset getNetcdfDataset(String matchPath)
* public InvCatalogImpl makeLatest(String matchPath, String reqPath, URI
catURI)
* abstract public InvCatalogImpl makeCatalog(String match, String
orgPath, URI catURI)

== InvDatasetGribFc

Keeps and manages a GribCollection or a TimePartition object. All
threads share this object

* *GribCollection* : keeps the indexRaf open, so as to not have to read
all Records into memory. all accesses to it are synchronized
* *TimePartition* manages a FileCache of Partition/GribCollection.
perhaps make Partition implement FileCacheable?

 
== GribCollection (GC)

[source,java]
----
 static public GribCollection factory(boolean isGrib1, CollectionManager dcm, CollectionManager.Force force, org.slf4j.Logger logger);
----

where Force controls the use of the *ncx* Index:

[source,java]
----
 public enum Force {
    always, // force writing new index
    test,   // test if new index is needed by scanning directory
    nocheck  // if index exists, use it
}
----

Relationship of CollectionManager and Index:

. collection is being monitored from outside; the index is correct,
and you just want to rebuild the GC from it: *force = nocheck.*
.. TDM sends *trigger=nocheck*
.. Very large datasets (NCDC) dont want to scan directories. startup=``nocheck'' NEW
. CollectionManager knows that the collection has changed, and that
the index needs to be updated: *force = always.*
.. rescan finds changes
. Figure it out yourself factory: *force=test*
.. CDM ?

*Problem 1*

. if you rebuild with nocheck and dont read in the dcm, then you cant
run a scan and see whats changed
.. so populate dcm from index (or)
.. invalidate dcm and always rebuild on test
. checkState() is called that calls dcm.scanIfNeeded() which will scan
if map is empty and !isStatic. isStatic apparently if theres no update
element.
. gribCollection.ncx has list of files, but not lastModified. Could go
to MFiles and increment ncx version. SOLUTION DONE - NEEDS TEST

*Problem* 2

* when index file needs to be rewritten by TDS

. new GC object is created
. index file rewritten
. old GC object is closed, which closes indexRaf

* the idea was to allow the old CG to be used while the new was being
rewritten. but its getting clobberred in place. so if a request is being
serviced while the index file is being rewritten, it will fail or get
spurious results.

* when TDM is doing it
. it clobbers the index file and then sends a message to the TDS
. TDS then reads new GC, closes old one

== TimePartition (TC)

* the overall TimePartition (subclass GribCollection) object is kept in
InvFcGrib object, with an open indexRaf. This has same pattern as the GC
* the TimePartition contains a collection of Partition objects, which
wrap GribCollections, each has an indexRaf once opened.
* a cache of Partition/GribCollection is kept in TimePartitionCache, so
they dont have to be reopened each time.
* TODO need to invalidate the cache when the index changes

=== Problem 1

* scan sees a change on TimePartition, sends update event to InvFc
* InvFc create a new TP(force=always)
* TP is trying to check if it needs to recreate the individual
partitions, but its only checking existing index date against new
collection files. So deletions wont be noticed.
. could check new file collection against index file collection
. could have option to only check latest.
. Always create all partitions SOLUTION FOR NOW
* TDM creates new TPs, sends trigger to TDS.
** should read in new indexes, not create

=== Problem 2

* could close the raf each time, and let OS manage cache, which it
probably does. put a read lock on it, and a write lock when you need to
rewrite. AutoCloseable
* Wont solve the TDM problem.
* possible solution write ncx.seqno.

does any of this affect NCDC?

=== GribXCollectionBuilder.readOrCreateIndex(Force)

. always
. test
. nocheck

[source,java]
----
 // force new index or test for new index needed
 boolean force = ((ff == CollectionManager.Force.always) || (ff == CollectionManager.Force.test && needsUpdate()));

 // otherwise, we're good as long as the index file exists
 File idx = gc.getIndexFile();
 if (force || !idx.exists() || !readIndex(idx.getPath()) )  {
   // write out index
   idx = gc.makeNewIndexFile(logger); // make sure we have a writeable index
   logger.info("{}: createIndex {}", gc.getName(), idx.getPath());
   createIndex(idx);

   // read back in index
   RandomAccessFile indexRaf = new RandomAccessFile(idx.getPath(), "r");
   gc.setIndexRaf(indexRaf);
   readIndex(indexRaf);
 }
----

if **test**, call __needsUpdate__() which uses _dcm.getFiles()_ and
_CollectionManager.hasChangedSince()_ :

[source,java]
----
 public boolean needsUpdate() {
   File idx = gc.getIndexFile();
   return !idx.exists() || needsUpdate(idx.lastModified());
 }
 private boolean needsUpdate(long idxLastModified) {
   CollectionManager.ChangeChecker cc = GribIndex.getChangeChecker();
   for (CollectionManager dcm : collections) {
     for (MFile mfile : dcm.getFiles()) {
       if (cc.hasChangedSince(mfile, idxLastModified)) return true;
     }
   }
   return false;
 }
----

_hasChangedSince()_ looks to see if the *gbx9* file exists or needs
updating:

[source,java]
----
public boolean hasChangedSince(MFile file, long when) {
 File idxFile = GribCollection.getIndexFile(file.getPath() + GBX9_IDX);
 if (!idxFile.exists()) return true;
 long idxLastModified =  idxFile.lastModified();
 if (idxLastModified < file.getLastModified()) return true;
 if (0 < when && when < idxLastModified) return true;
 return false;
}
----

check createIndex() logic


== motherlode instructions

=== To restart the TDM:

. log in to motherlode
. cd ~caron
. sudo su ldm
. clean up logs
.. rm saveX/*
.. mv *.log saveX
.. mv tdm.log* save
. sh ./runTdm.sh &

=== TDM logs

. specific collections are in <collectionName>.log
. running tdm output is in tdm.log; these roll over every day

=== TDM source code

* in github under tdm module
* tdm-4.3 jar is built by maven
* configuration file is
*tdm\src\main\resources\resources\application-config.xml*
** currently set to trigger 8081 and 9080
